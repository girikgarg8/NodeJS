There can be combinatin of different types of databases used in any company.

Just a side note:

===Error first callback===
Error-First Callback in Node.js is a function which either returns an error object or any successful data returned by the function.

The first argument in the function is reserved for the error object. If any error has occurred during the execution of the function, it will be returned by the first argument.
The second argument of the callback function is reserved for any successful data returned by the function. If no error occurred then the error object will be set to null.

for example, while using file system in nodejs, it takes error first callback

const fs = require("fs");


==Taking back the discussion to databases===

No kind of database (SQL or NoSQL) is perfect for all use cases.

What are NoSQL databases? Nosql databases store data in non-tabular form, such as documents, key-value pairs or graph.

MongoDB stores the data in form of JSON like documents.

For general knowledge: PostgreSQL stores the database entries in the form of json objects (not json-like, it's actual json)

In which use case should we prefer SQL over NoSQL systems? Will be discussed in detail, for now, one point is that NoSQL databases are suited for horizontal scaling and distributed systems? The reason which ChatGPT gives is:

SQL databases can be used for horizontal scaling, but they are not as well-suited for this task as NoSQL databases. The main reason for this is that SQL databases are typically designed to run on a single server and handle vertical scaling (scaling up by adding more resources to a single server), rather than horizontal scaling (scaling out by adding more servers to a distributed system).

One of the main challenges with scaling SQL databases horizontally is maintaining data consistency across multiple nodes. With a distributed system, multiple copies of the data may exist on different servers, which can lead to issues with data consistency and concurrency control. Ensuring that all nodes have access to the same data, and that updates to the data are properly synchronized, can be a complex and challenging task.

Another challenge with scaling SQL databases horizontally is that traditional SQL queries are optimized for single-server databases, and may not perform as well when run across multiple nodes. This can lead to performance issues and slow query times as the system scales out.

Overall, while it is possible to scale SQL databases horizontally, NoSQL databases are generally considered to be a better fit for this task due to their distributed architecture, flexible data model, and eventual consistency approach.

MongoDB community edition is the CLI for using MongoDB.
MongoDB compass is a GUI for MongoDB.

Tables in SQL==>Collections  in MongoDB
Rows in SQL=>Documents in MongoDB


In order to interact with mongoose, we will use object document model (ODM) called mongoose, just like we were using ORM to interact with MySQL database.
We use ODM because we don't want to write raw mongoose queries.

Mongoose is specific to nodejs only, means to say it is a ODM which is specific to nodejs only

Sequelise manages the connections automatically,but in case of mongoose we have to define the connection ourselves

Why is there a need of defining a schema in case of MongoDB? In relational databases, schema is necessary because every attribute is required in each row, but in NoSQL databases, defining all the attributes like name, phone number is not necessary in each document, but the use of schema is to make sure that there's consistent object sharing between different communication applications, like for example if I am communicating with database, then I would be atleast sure that what fields I can expect as response

In MongoDB, in order to use time stamps like createdAt and updatedAt, I can specify timestamps:true in the model, MongoDB will automaticaly insert the updatedAt and createdAt timestamps

Unless and until we don't create the first document(row) in the collection(table), ntil then the model will not be created in MongoDB


In a MongoDB schema, id and __v are two commonly used fields:

id: This field is automatically added to every MongoDB document as a unique identifier. It is a 12-byte hexadecimal string that is generated by MongoDB when a new document is inserted. You can also specify your own value for this field when inserting new documents.
For example, suppose we have a users collection, and we insert a new document with the following data:

json
Copy code
{
  "_id": "6051b8a360a46f16b356f0c1",
  "name": "Alice",
  "age": 30
}
In this case, the _id field is set to the value "6051b8a360a46f16b356f0c1". This value is unique to this document and can be used to retrieve or update it later.

__v: This field is used by Mongoose, a popular MongoDB library for Node.js, to track the version of a document. It is an integer value that starts at 0 and is incremented every time the document is updated.
For example, suppose we have a posts collection, and we insert a new document with the following data:


{
  "title": "My first post",
  "content": "This is my first post on this blog"
}
In this case, the __v field is not specified, so it is automatically set to 0. If we update this document later, the __v field will be incremented:


{
  "_id": "6051b8a360a46f16b356f0c2",
  "title": "My first post",
  "content": "This is an updated version of my first post",
  "__v": 1
}
In this case, the __v field has been incremented to 1 to indicate that this is a newer version of the document.

Overall, the id field is used as a unique identifier for each document, while the __v field is used by Mongoose to track the version of a document.

By default, when I execute a find and update query, it will update the document but it will return the old document (before updation), to return the new document I can specify new:true in the options

Some awesome stuffs about NoSQL database:

1) I can keep the attributes as object, like comments atribute can be an object, it is not possible while using relational databases
2) NoSQL databases are easy to start with, in a project
3) The structure of the table need not to be known at the beginning of the project, it can be updated on the fly

Another big advantage of using MongoDB is that I can use one schema inside another schema, in SQL databases, to get same functionality I have to use joins in tables.

Yes, you can use one schema inside another schema in MongoDB using the concept of embedding. In MongoDB, you can embed one schema (let's call it the "child schema") inside another schema (let's call it the "parent schema") by defining the child schema as a field in the parent schema.

For example, suppose you have a parent schema called "User" and a child schema called "Address". You can embed the Address schema inside the User schema by defining the Address schema as a field in the User schema:

const addressSchema = new mongoose.Schema({
  street: String,
  city: String,
  state: String,
  zip: String
});

const userSchema = new mongoose.Schema({
  name: String,
  email: String,
  password: String,
  address: addressSchema
});


In the above example, the Address schema is defined as a field in the User schema using the address: addressSchema syntax. This means that each user document will contain an embedded address document.


The save() function is used to save the document to the database. Using this function, new documents can be added to the database. (In terms of relational databases, I can think of save() as adding a new row to the table)

===Continuing MongoDB===

A small optimization that can be done while working on MongoDB, is using lean() function.

What exactly is this function and why is it needed? Need: Whenever I exceute a mongodb query, it returns me a mongoose document. 
Documents are much heavier than vanilla JavaScript objects, because they have a lot of internal state for change tracking.
But I can directly return a javascript object by using the lean function(), it helps me in performance improvement for executing the queries. 


In SQL, pagination refers to the process of breaking up a large set of query results into smaller, more manageable pages. This is useful when you are working with a large dataset and want to display it to users in a way that is easy to read and navigate.

Pagination typically involves two steps: first, retrieving a subset of the results based on a specified page size and page number, and second, displaying the subset of results to the user.

Here's an example of how you can implement pagination in SQL using the LIMIT and OFFSET clauses:

Suppose you have a table called employees that contains a list of employee records, and you want to display the records in groups of 10 employees per page. Here's how you can do it:

SELECT * FROM employees
LIMIT 10 OFFSET 0; -- retrieves first 10 records

SELECT * FROM employees
LIMIT 10 OFFSET 10; -- retrieves second 10 records

SELECT * FROM employees
LIMIT 10 OFFSET 20; -- retrieves third 10 records
In this example, the LIMIT clause specifies the maximum number of records to retrieve, and the OFFSET clause specifies the starting point for retrieving records. By changing the OFFSET value, you can retrieve different subsets of records.

When you display the records to the user, you can provide links or buttons to navigate between the pages, based on the total number of records and the page size.

Pagination is commonly used in web applications that display lists of data to users, such as search results, product listings, or news articles. By breaking up the results into smaller, more manageable pages, you can provide a better user experience and improve the performance of your application.

Performing pagination in the database query has several advantages over fetching all the rows from the table and then doing pagination in the frontend app:

Faster performance: If the table has a large number of rows, fetching all the rows from the database can be a time-consuming and resource-intensive process. Performing pagination in the database query ensures that only the necessary rows are fetched, reducing the amount of data that needs to be transferred over the network and improving the overall performance of the application.

Reduced network traffic: By fetching only the necessary rows from the database, performing pagination in the query reduces the amount of data that needs to be transferred over the network. This can be especially beneficial in cases where the application is used over a slow or unreliable network connection.

Lower memory usage: Fetching a large number of rows from the database and holding them in memory can be memory-intensive and can cause performance issues. Performing pagination in the database query ensures that only the necessary rows are fetched, reducing the amount of memory used by the application.

Easier to maintain: If the pagination logic is implemented in the database query, it is easier to modify or update the pagination behavior in the future. On the other hand, if the pagination logic is implemented in the frontend app, any changes to the pagination behavior would require modifying the application code.

==> Similarly, now we are going to do pagination in MongoDB database, for this I use two functions named skip and limit in javascript===

In MongoDB, a virtual is a computed property that is not stored in the database but can be accessed as if it were a regular field. Virtual fields are defined in the schema and are computed based on other fields or data in the document.

===>What are virtuals in MongoDB?

Virtual fields can be useful in situations where you need to compute a value on the fly based on data stored in the database. For example, you might want to calculate the total price of an order based on the prices of individual items in the order.

To define a virtual field in a MongoDB schema, you can use the virtual method provided by Mongoose, the popular object modeling tool for Node.js. Here's an example:

const mongoose = require('mongoose');

const OrderSchema = new mongoose.Schema({
  items: [{
    name: String,
    price: Number
  }]
});

OrderSchema.virtual('total').get(function() {
  return this.items.reduce((total, item) => total + item.price, 0);
});

const Order = mongoose.model('Order', OrderSchema);

What is database indexing? Database indexing is the technique by which we can optimize the result of a DBMS query, by reducing the number of disk accesses required.

Indexing is supported in both relational and non-relational databases

The official documentation of MongoDB says: 'Without indexes, MongoDB must perform a collection scan i.e. scan every dcuement in a collection, to select those documents that match the query statement'

Another example of virrtuals is that weith each document, I can use 'id', even though the 'id' attrbiute is not present inside the document.

===> What is a trigger, and how do we use triggers in MongoDB?

Formal definition of trigger: A trigger is a stored procedure in database which automatically invokes whenever a special event in the database occurs.

Use case of trigger in the previous project of Airplane booking: I fired a trigger each time the details of a user were entered, in order to hash the password using bcryptjs (Triggers are known as hooks in sequelize)

Internally, indexes are special data structures thata store a small portion of the collection's data set in an easy to traverse form.(example: B tree or B+ tree)

Choice of index depends upon the usecase.

There's no concept of migrations in MongoDB, because we don't care about the structure of the table.

Unit tetsing and integrating testing is exepceted from backend engineer, QA engineers are different in each company

The basics in each testing framework are same: concepts of mocks.( Concepts are same in each language, just the libraries are different)

Java coding is lot of annotation based and dependency injection based

===Setting up the projects and requirements===

For storing images and videos, we'll be using S3 static storage.

For authorization, we would be using  passport js library, we won't be coding the authorization part ourselves (unlike the airline booking project)

As the hashtag schema can grow very big in size, we'll try to index it for faster query answer retrieval.

For extracting the hashtags from tweet, I'll be using regular expressions.

Logic for adding hashtags in tweets:

1.  Bulkcreate tags in mongoose
2. Filter title of hashtag based on multiple tags (if the user passes 3 hashtags in the tweet, and 2 of these already exist in the database,I will only be creating that tag which doesn't exist in the database)
3. How to add tweet ID inside all the hastags


Aggregation pipelines in MongoDB: Firstly, what are aggregation functions in SQL or ny other database? This function performs calculations one or more values and returns a single value.

Now, what are aggregation pipelines? Aggregation pipelines can have one or more "stages". The order of these stages are important. Each stage acts upon the results of the previous stage.

===Adding logic for tweets===

Difference between forEach and map() function in javascript:

The map() method returns a new array, whereas the forEach() method does not return a new array.

The map() method is used to transform the elements of an array, whereas the forEach() method is used to loop through the elements of an array.

We'll now refactor the CommonJS code into ES6 code, for that I will specify type as module in the package.json file, and make the necessary code changes for import and export

Added logic for tweets

===Likes and comments===

If the backend code is not API driven, and at a later stage, I decide to make a mobile app, then the backend code needs a lot of refactoring, because in mobile app, because we need to process JSON responses too in the mobile app 

API driven development means practicing of desinging and building AIs first, thren creating the rest of an application around them.

Very important aspect: Like can be done on a comment as well as on a tweet. So, I will make the database design of Like model as something like:

https://dev.to/chubbystrings/dynamic-model-referencing-with-mongoose-41jf#:~:text=The%20refPath%20option%20is%20a%20more%20sophisticated%20alternative,configure%20what%20model%20Mongoose%20uses%20for%20each%20doc. Read this article, it explains about dynamic model referencing

One of the errors which we encountered during the project was, due to treating runnables as promises while using Mongoose and MongoDB, all promises are thenables, but not all thenables are promises. See this article: https://javascript.plainenglish.io/whats-the-difference-between-a-thenable-and-a-promise-74d697bc9c79

Read this article: https://javascript.plainenglish.io/the-benefit-of-the-thenable-object-in-javascript-78107b697211, beautifully explained

===Adding comments model===

Agenda pending

1- Comments and Likes (Done)
2- Passport user authorization
3- Misc and S3 image upload
4- Testing of app
5- Web sockets-chat app 1
6- Chat app 2
7- Docker|deployment| CICD
8- Grpc-> 2 services| client, server| what is protobuf, and why didn't we use GRPC in the projects till now
9- Redis caching
10- Extra (How to give a high level system design interview, iterator generator in javascript)


Left at 1:21:17 (passport user authorization)

===Notes from adding authentication===

Wew are going to use passport-jwt (which works on JSON web tokens) in our project for authenticating the user.

There are two separate packages which I need for the authentication: passport-jwt is specific package which tells about the speciif strategy to be used, and the passport package which is the general package 